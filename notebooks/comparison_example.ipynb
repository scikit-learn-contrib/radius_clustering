{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4acb9df3",
   "metadata": {},
   "source": [
    "# Comparison of Radius Clustering with KMeans on the samples Dataset\n",
    "\n",
    "\n",
    "This example is meant to illustrate the use of the Radius clustering library on several datasets.\n",
    "\n",
    "The example includes:\n",
    "1. Loading the datasets\n",
    "2. Applying Radius clustering and k-means clustering\n",
    "3. Visualizing the clustering results\n",
    "\n",
    "This example serves as a simple introduction to using the Radius clustering library on well-known datasets.\n",
    "\n",
    "**Author: Haenn Quentin**\n",
    "\n",
    "**@SPDX-License-Identifier: MIT**\n",
    "\n",
    "\n",
    "\n",
    "## 1. Load the Iris dataset\n",
    "\n",
    "We start by loading the Iris dataset using the `fetch_openml` function from `sklearn.datasets`.\n",
    "The Iris dataset is a well-known dataset that contains 150 samples of iris flowers.\n",
    "Each sample has 4 features: sepal length, sepal width, petal length, and petal width.\n",
    "The dataset is labeled with 3 classes: setosa, versicolor, and virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from radius_clustering import RadiusClustering\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84938fd",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Visualize the Iris dataset\n",
    "\n",
    "\n",
    "We can visualize the Iris dataset by plotting the dataset. We use PCA to reduce the dimensionality to 3D and plot the dataset in a 3D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f37b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import mpl_toolkits.mplot3d\n",
    "\n",
    "# Reduce the dimensionality of the dataset to 3D using PCA\n",
    "pca = PCA(n_components=3)\n",
    "iris_reduced = pca.fit_transform(X)\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\", elev=48, azim=134)\n",
    "ax.scatter(\n",
    "    iris_reduced[:, 0],\n",
    "    iris_reduced[:, 1],\n",
    "    iris_reduced[:, 2],\n",
    "    c=y,\n",
    "    cmap=\"Dark2\",\n",
    "    s=40,\n",
    ")\n",
    "# Set plot labels\n",
    "ax.set_title(\"Iris dataset in first 3 PCA components\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "\n",
    "# Hide tick labels\n",
    "ax.xaxis.set_ticklabels([])\n",
    "ax.yaxis.set_ticklabels([])\n",
    "ax.zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38d50b",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Compute Clustering with Radius Clustering\n",
    "\n",
    "We can now apply Radius clustering to the Iris dataset.\n",
    "We create an instance of the `RadiusClustering` class and fit it to the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "rad = RadiusClustering(manner=\"exact\", radius=1.43)\n",
    "t0 = time.time()\n",
    "rad.fit(X)\n",
    "t_rad = time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653845e",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Compute KMeans Clustering for Comparison\n",
    "\n",
    "We also apply KMeans clustering to the Iris dataset for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_means = KMeans(n_clusters=3, n_init=10)\n",
    "t0 = time.time()\n",
    "k_means.fit(X)\n",
    "t_kmeans = time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1072a7f",
   "metadata": {},
   "source": [
    "## 5. Establishing parity between clusters\n",
    "\n",
    "We want to have the same color for the same cluster in both plots.\n",
    "We can achieve this by matching the cluster labels of the Radius clustering and the KMeans clustering.\n",
    "First we define a function to retrieve the cluster centers from the Radius clustering and KMeans clustering and\n",
    "match them pairwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac48cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_order_labels(kmeans, rad, data):\n",
    "    centers1_cpy = kmeans.cluster_centers_.copy()\n",
    "    centers2_cpy = data[rad.centers_].copy()\n",
    "    order = []\n",
    "    # For each center in the first clustering, find the closest center in the second clustering\n",
    "    for center in centers1_cpy:\n",
    "        match = pairwise_distances_argmin([center], centers2_cpy)\n",
    "        # if there is only one center left, assign it to the last cluster label not yet assigned\n",
    "        if len(centers2_cpy) == 1:\n",
    "            for i in range(len(centers1_cpy)):\n",
    "                if i not in order:\n",
    "                    order.append(i)\n",
    "                    break\n",
    "            break\n",
    "        # get coordinates of the center in the second clustering\n",
    "        coordinates = centers2_cpy[match]\n",
    "        # find the closest point in the data to the center to get the cluster label\n",
    "        closest_point = pairwise_distances_argmin(coordinates, data)\n",
    "        match_label = rad.labels_[closest_point]\n",
    "        # remove the center from the second clustering\n",
    "        centers2_cpy = np.delete(centers2_cpy, match, axis=0)\n",
    "        # add the cluster label to the order\n",
    "        order.append(int(match_label[0]))\n",
    "    return order\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "\n",
    "rad_centers_index = np.array(rad.centers_)\n",
    "order = get_order_labels(k_means, rad, X)\n",
    "\n",
    "kmeans_centers = k_means.cluster_centers_\n",
    "rad_centers = rad_centers_index[order]\n",
    "rad_centers_coordinates = X[rad_centers]\n",
    "\n",
    "# Pair the cluster labels\n",
    "kmeans_labels = pairwise_distances_argmin(X, kmeans_centers)\n",
    "rad_labels = pairwise_distances_argmin(X, rad_centers_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428447c",
   "metadata": {},
   "source": [
    "### Plotting the results and the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c095ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "\n",
    "# KMeans\n",
    "ax = fig.add_subplot(1, 3, 1, projection=\"3d\", elev=48, azim=134, roll=0)\n",
    "\n",
    "ax.scatter(\n",
    "    iris_reduced[:, 0],\n",
    "    iris_reduced[:, 1],\n",
    "    iris_reduced[:, 2],\n",
    "    c=kmeans_labels,\n",
    "    cmap=\"Dark2\",\n",
    "    s=40,\n",
    ")\n",
    "# adapting center coordinates to the 3D plot\n",
    "kmeans_centers = pca.transform(kmeans_centers)\n",
    "ax.scatter(\n",
    "    kmeans_centers[:, 0],\n",
    "    kmeans_centers[:, 1],\n",
    "    kmeans_centers[:, 2],\n",
    "    c=\"r\",\n",
    "    s=200,\n",
    ")\n",
    "ax.set_title(\"KMeans\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "\n",
    "ax.text3D(-3.5, 3, 1.0, \"train time: %.2fs\\ninertia: %f\" % (t_kmeans, k_means.inertia_))\n",
    "\n",
    "# MDS\n",
    "ax = fig.add_subplot(1, 3, 2, projection=\"3d\", elev=48, azim=134, roll=0)\n",
    "ax.scatter(\n",
    "    iris_reduced[:, 0],\n",
    "    iris_reduced[:, 1],\n",
    "    iris_reduced[:, 2],\n",
    "    c=rad_labels,\n",
    "    cmap=\"Dark2\",\n",
    "    s=40,\n",
    ")\n",
    "# adapting center coordinates to the 3D plot\n",
    "rad_centers_coordinates = pca.transform(rad_centers_coordinates)\n",
    "ax.scatter(\n",
    "    rad_centers_coordinates[:, 0],\n",
    "    rad_centers_coordinates[:, 1],\n",
    "    rad_centers_coordinates[:, 2],\n",
    "    c=\"r\",\n",
    "    s=200,\n",
    ")\n",
    "ax.set_title(\"MDS Clustering\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "ax.text3D(-3.5, 3, 0.0, \"train time: %.2fs\" % t_rad)\n",
    "\n",
    "# Initialize the different array to all False\n",
    "different = rad_labels == 4\n",
    "ax = fig.add_subplot(1, 3, 3, projection=\"3d\", elev=48, azim=134, roll=0)\n",
    "\n",
    "for k in range(3):\n",
    "    different += (kmeans_labels == k) != (rad_labels == k)\n",
    "\n",
    "identical = np.logical_not(different)\n",
    "ax.scatter(\n",
    "    iris_reduced[identical, 0], iris_reduced[identical, 1], color=\"#bbbbbb\", marker=\".\"\n",
    ")\n",
    "ax.scatter(iris_reduced[different, 0], iris_reduced[different, 1], color=\"m\")\n",
    "ax.set_title(\"Difference\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c4fcf",
   "metadata": {},
   "source": [
    "## Another difference plot\n",
    "\n",
    "As we saw, the difference plot is not very informative using Iris.\n",
    "We'll use a different dataset to show the difference plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "pca = PCA(n_components=3)\n",
    "wine_reduced = pca.fit_transform(X)\n",
    "\n",
    "# Compute clustering with MDS\n",
    "\n",
    "rad = RadiusClustering(manner=\"exact\", radius=232.09)\n",
    "t0 = time.time()\n",
    "rad.fit(X)\n",
    "t_rad = time.time() - t0\n",
    "\n",
    "# Compute KMeans clustering for comparison\n",
    "\n",
    "k_means = KMeans(n_clusters=3, n_init=10)\n",
    "t0 = time.time()\n",
    "k_means.fit(X)\n",
    "t_kmeans = time.time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929dee4",
   "metadata": {},
   "source": [
    "## Reapplying the same process as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24449b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_centers_index = np.array(rad.centers_)\n",
    "order = get_order_labels(k_means, rad, X)\n",
    "\n",
    "kmeans_centers = k_means.cluster_centers_\n",
    "rad_centers = rad_centers_index[order]\n",
    "rad_centers_coordinates = X[rad_centers]\n",
    "\n",
    "# Pair the cluster labels\n",
    "kmeans_labels = pairwise_distances_argmin(X, kmeans_centers)\n",
    "rad_labels = pairwise_distances_argmin(X, rad_centers_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3accac5b",
   "metadata": {},
   "source": [
    "## Plotting the results and the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39235d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.subplots_adjust(left=0.02, right=0.98, bottom=0.05, top=0.9)\n",
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "\n",
    "# KMeans\n",
    "ax = fig.add_subplot(1, 3, 1, projection=\"3d\", elev=48, azim=134, roll=0)\n",
    "\n",
    "ax.scatter(\n",
    "    wine_reduced[:, 0],\n",
    "    wine_reduced[:, 1],\n",
    "    wine_reduced[:, 2],\n",
    "    c=kmeans_labels,\n",
    "    cmap=\"Dark2\",\n",
    "    s=40,\n",
    ")\n",
    "# adapting center coordinates to the 3D plot\n",
    "kmeans_centers = pca.transform(kmeans_centers)\n",
    "ax.scatter(\n",
    "    kmeans_centers[:, 0],\n",
    "    kmeans_centers[:, 1],\n",
    "    kmeans_centers[:, 2],\n",
    "    c=\"r\",\n",
    "    s=200,\n",
    ")\n",
    "ax.set_title(\"KMeans\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "\n",
    "ax.text3D(\n",
    "    60.0, 80.0, 0.0, \"train time: %.2fs\\ninertia: %f\" % (t_kmeans, k_means.inertia_)\n",
    ")\n",
    "\n",
    "# MDS\n",
    "ax = fig.add_subplot(1, 3, 2, projection=\"3d\", elev=48, azim=134, roll=0)\n",
    "ax.scatter(\n",
    "    wine_reduced[:, 0],\n",
    "    wine_reduced[:, 1],\n",
    "    wine_reduced[:, 2],\n",
    "    c=rad_labels,\n",
    "    cmap=\"Dark2\",\n",
    "    s=40,\n",
    ")\n",
    "# adapting center coordinates to the 3D plot\n",
    "rad_centers_coordinates = pca.transform(rad_centers_coordinates)\n",
    "ax.scatter(\n",
    "    rad_centers_coordinates[:, 0],\n",
    "    rad_centers_coordinates[:, 1],\n",
    "    rad_centers_coordinates[:, 2],\n",
    "    c=\"r\",\n",
    "    s=200,\n",
    ")\n",
    "ax.set_title(\"MDS Clustering\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "ax.text3D(60.0, 80.0, 0.0, \"train time: %.2fs\" % t_rad)\n",
    "\n",
    "# Initialize the different array to all False\n",
    "different = rad_labels == 4\n",
    "ax = fig.add_subplot(1, 3, 3, projection=\"3d\", elev=48, azim=134, roll=0)\n",
    "\n",
    "for k in range(3):\n",
    "    different += (kmeans_labels == k) != (rad_labels == k)\n",
    "\n",
    "identical = np.logical_not(different)\n",
    "ax.scatter(\n",
    "    wine_reduced[identical, 0], wine_reduced[identical, 1], color=\"#bbbbbb\", marker=\".\"\n",
    ")\n",
    "ax.scatter(wine_reduced[different, 0], wine_reduced[different, 1], color=\"m\")\n",
    "ax.set_title(\"Difference\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_zticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1172f38",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this example, we applied Radius clustering to the Iris and Wine datasets and compared it with KMeans clustering.\n",
    "We visualized the clustering results and the difference between the two clustering algorithms.\n",
    "We saw that Radius Clustering can lead to smaller clusters than kmeans, which produces much more equilibrate clusters.\n",
    "The difference plot can be very useful to see where the two clustering algorithms differ."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
